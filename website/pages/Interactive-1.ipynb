{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to base (Python 3.10.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SynchronousOnlyOperation",
     "evalue": "You cannot call this from an async context - use a thread or sync_to_async.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSynchronousOnlyOperation\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[1;32m/home/rohit/news/website/pages/top5.py:32\u001b[0m\n\u001b[1;32m     29\u001b[0m channels \u001b[39m=\u001b[39m NewsChannel\u001b[39m.\u001b[39mobjects\u001b[39m.\u001b[39mall()\n\u001b[1;32m     31\u001b[0m titles \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m \u001b[39mfor\u001b[39;00m channel \u001b[39min\u001b[39;00m channels:\n\u001b[1;32m     33\u001b[0m     \u001b[39m# Fetch the latest 5 video titles from this channel that were published in the last 4 hours\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     videos \u001b[39m=\u001b[39m Video\u001b[39m.\u001b[39mobjects\u001b[39m.\u001b[39mfilter(channel\u001b[39m=\u001b[39mchannel, published_date__range\u001b[39m=\u001b[39m(time_4_hours_ago, now))\u001b[39m.\u001b[39morder_by(\u001b[39m'\u001b[39m\u001b[39m-published_date\u001b[39m\u001b[39m'\u001b[39m)[:\u001b[39m5\u001b[39m]\n\u001b[1;32m     35\u001b[0m     \u001b[39m# Append these titles to our master list\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/django/db/models/query.py:398\u001b[0m, in \u001b[0;36mQuerySet.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    384\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39m    The queryset iterator protocol uses three nested iterators in the\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[39m    default case:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39m           - Responsible for turning the rows into model objects.\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_all()\n\u001b[1;32m    399\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result_cache)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/django/db/models/query.py:1881\u001b[0m, in \u001b[0;36mQuerySet._fetch_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1879\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fetch_all\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1880\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result_cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1881\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result_cache \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterable_class(\u001b[39mself\u001b[39;49m))\n\u001b[1;32m   1882\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prefetch_related_lookups \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prefetch_done:\n\u001b[1;32m   1883\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prefetch_related_objects()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/django/db/models/query.py:91\u001b[0m, in \u001b[0;36mModelIterable.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m compiler \u001b[39m=\u001b[39m queryset\u001b[39m.\u001b[39mquery\u001b[39m.\u001b[39mget_compiler(using\u001b[39m=\u001b[39mdb)\n\u001b[1;32m     89\u001b[0m \u001b[39m# Execute the query. This will also fill compiler.select, klass_info,\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39m# and annotations.\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m results \u001b[39m=\u001b[39m compiler\u001b[39m.\u001b[39;49mexecute_sql(\n\u001b[1;32m     92\u001b[0m     chunked_fetch\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunked_fetch, chunk_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size\n\u001b[1;32m     93\u001b[0m )\n\u001b[1;32m     94\u001b[0m select, klass_info, annotation_col_map \u001b[39m=\u001b[39m (\n\u001b[1;32m     95\u001b[0m     compiler\u001b[39m.\u001b[39mselect,\n\u001b[1;32m     96\u001b[0m     compiler\u001b[39m.\u001b[39mklass_info,\n\u001b[1;32m     97\u001b[0m     compiler\u001b[39m.\u001b[39mannotation_col_map,\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m     99\u001b[0m model_cls \u001b[39m=\u001b[39m klass_info[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/django/db/models/sql/compiler.py:1560\u001b[0m, in \u001b[0;36mSQLCompiler.execute_sql\u001b[0;34m(self, result_type, chunked_fetch, chunk_size)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnection\u001b[39m.\u001b[39mchunked_cursor()\n\u001b[1;32m   1559\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1560\u001b[0m     cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection\u001b[39m.\u001b[39;49mcursor()\n\u001b[1;32m   1561\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1562\u001b[0m     cursor\u001b[39m.\u001b[39mexecute(sql, params)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/django/utils/asyncio.py:24\u001b[0m, in \u001b[0;36masync_unsafe.<locals>.decorator.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mDJANGO_ALLOW_ASYNC_UNSAFE\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 24\u001b[0m         \u001b[39mraise\u001b[39;00m SynchronousOnlyOperation(message)\n\u001b[1;32m     25\u001b[0m \u001b[39m# Pass onward.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mSynchronousOnlyOperation\u001b[0m: You cannot call this from an async context - use a thread or sync_to_async."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.append('/home/rohit/news/website')\n",
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "import os\n",
    "import django\n",
    "from django.utils import timezone\n",
    "from datetime import timedelta\n",
    "\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'website.settings')  \n",
    "django.setup()\n",
    "from collections import Counter as CollectionsCounter\n",
    "from pages.models import NewsChannel, Video, TrendingTopic\n",
    "import openai\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Get the current time\n",
    "now = timezone.now()\n",
    "\n",
    "# Get the time 4 hours ago and 2 days ago\n",
    "time_4_hours_ago = now - timedelta(hours=8)\n",
    "time_2_days_ago = now - timedelta(days=2)\n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Fetch all video titles from your database that were published in the last 4 hours\n",
    "videos = Video.objects.filter(published_date__range=(time_4_hours_ago, now))\n",
    "channels = NewsChannel.objects.all()\n",
    "\n",
    "titles = []\n",
    "for channel in channels:\n",
    "    # Fetch the latest 5 video titles from this channel that were published in the last 4 hours\n",
    "    videos = Video.objects.filter(channel=channel, published_date__range=(time_4_hours_ago, now)).order_by('-published_date')[:5]\n",
    "    # Append these titles to our master list\n",
    "    for video in videos:\n",
    "        title = video.title\n",
    "        # Translate the title to English\n",
    "        translated_title = translator.translate(title, dest='en').text\n",
    "        titles.append(translated_title)\n",
    "\n",
    "# Fetch the topics from all videos\n",
    "all_topics = [video.topic for video in Video.objects.all()]\n",
    "\n",
    "# Calculate the frequency of each topic\n",
    "topic_counter = CollectionsCounter(all_topics)\n",
    "\n",
    "# Filter out blank and dash (\"-\") topics\n",
    "for topic in list(topic_counter):  # Use list to avoid 'dictionary changed size during iteration' error\n",
    "    if topic == \"\" or topic == \"-\":\n",
    "        del topic_counter[topic]\n",
    "\n",
    "# Get the 5 most common topics from TrendingTopic model\n",
    "most_common_topics = TrendingTopic.objects.order_by('rank')[:5]\n",
    "\n",
    "# Convert most_common_topics to a list of tuples for consistency with your old code\n",
    "most_common_topics = [(topic.topic, topic.rank) for topic in most_common_topics]\n",
    "\n",
    "print(f\"Most common topics: {most_common_topics}\")\n",
    "topics_str = ' '.join([f'{i+1}. {topic[0]}' for i, topic in enumerate(most_common_topics)])\n",
    "system_message = f\"You are a sophisticated AI model trained in news topic extraction. Please give the topics in the format example: {topics_str}\"\n",
    "\n",
    "all_titles = '\\n'.join(titles)\n",
    "\n",
    "# Remember to limit the length of the input as the API has a maximum token limit\n",
    "max_len = 10000\n",
    "if len(all_titles) > max_len:\n",
    "    all_titles = all_titles[:max_len]\n",
    "print(all_titles)\n",
    "\n",
    "# Retry up to 5 times\n",
    "for retry in range(5):\n",
    "    while True:  # Continue until we get a reply under 160 characters\n",
    "        try:\n",
    "            # Construct the conversation with the AI model\n",
    "            completion = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-16k\",\n",
    "                messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_message},\n",
    "                        {\"role\": \"user\", \"content\": f\"I have a list of news titles from the last 4 hours: {all_titles}. Can you analyze them and tell me the five unique topics that these titles seem to be about? The topics should be in Title Case without hashtags, and should be ordered by frequency. \"},\n",
    "                ],\n",
    "                \n",
    "            )\n",
    "            # Extract the model's reply\n",
    "            reply = completion.choices[0].message['content']\n",
    "\n",
    "            # Check if the reply is under 160 characters\n",
    "            if len(reply) <= 200:\n",
    "                break\n",
    "            print(f\"Generated reply was too long, retrying...\")\n",
    "            print(f\"Generated reply: {reply}\")\n",
    "            time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "        except Exception as e:\n",
    "            print(f\"Error on attempt {retry+1}: {e}\")\n",
    "            \n",
    "\n",
    "    # If we got a reply under 160 characters, break out of the retry loop\n",
    "    if len(reply) <= 200:\n",
    "        break\n",
    "    print(f\"Retry #{retry+1} failed, waiting 5 seconds before next attempt...\")\n",
    "    time.sleep(5)  # Wait for 5 seconds before next retry\n",
    "\n",
    "# Split the reply into topics\n",
    "topics = reply.split('\\n')\n",
    "# Remove numbers and dots from the topics\n",
    "topics = [topic.split('. ')[1] if '. ' in topic else topic for topic in topics]\n",
    "\n",
    "# Fetch the old topics from the last two days\n",
    "old_topics = Video.objects.filter(published_date__range=(time_2_days_ago, now)).values_list('topic', flat=True)\n",
    "\n",
    "# Set a threshold for the similarity\n",
    "similarity_threshold = 50\n",
    "\n",
    "# Update the TrendingTopic model\n",
    "# Update the TrendingTopic model\n",
    "for i, (topic, _) in enumerate(most_common_topics):\n",
    "    # Initialize max_similarity and similar_old_topic\n",
    "    max_similarity = -1\n",
    "    similar_old_topic = None\n",
    "\n",
    "    # Check if the topic already exists in the old topics using fuzzy matching\n",
    "    for old_topic in old_topics:\n",
    "        similarity = fuzz.ratio(topic, old_topic)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            similar_old_topic = old_topic\n",
    "\n",
    "    if max_similarity > similarity_threshold:\n",
    "        # If similar old topic found with the highest similarity score, replace new topic with old topic\n",
    "        print(f\"New topic '{topic}' is similar to old topic '{similar_old_topic}' with a similarity score of {max_similarity}, replacing.\")\n",
    "        topic = similar_old_topic\n",
    "\n",
    "    # Update the TrendingTopic model with the new or old topic\n",
    "    trending_topic, created = TrendingTopic.objects.get_or_create(rank=i+1)\n",
    "    trending_topic.topic = topic\n",
    "    trending_topic.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
